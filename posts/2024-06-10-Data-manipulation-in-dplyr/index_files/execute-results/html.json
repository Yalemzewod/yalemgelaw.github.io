{
  "hash": "3a09042c606cc1134d74f9a60c6e92c1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data manipulation: dplyr\"\ndescription: |\n  Basic data cleaning and management in dplyr\nauthor: \n  - name: Yalemzewod Gelaw\n    url: https://yalemzewodgelaw.com/\n    orcid: 0000-0002-5338-586 \ndate: 2024-06-12\nimage: \"media/pc.png\"\nslug: beginner’s guide\ncategories: [RStudio, Data management]\ntoc: true\ntoc-depth: 4\ncss: index.css\nnumber-sections: false\nhighlight-style: github\nexecute:\n  echo: false\n  eval: true\nformat:\n  html:\n    self-contained: true\n    code-fold: true\n    code-summary: \"Show the code\"\n    code-tools: true\n    theme: united \nknitr: \n opts_knit: \n   warning: false\n   message: false\n---\n\n\n<head>\n\n\n```{=html}\n<script async src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7959266255261935\" crossorigin=\"anonymous\"></script>\n```\n\n</head>\n\n# Data management in dplyr\n\nIn this section, I will discuss about data management process, basic data cleaning and management in `dplyr`.\n\nData can be defined as a collection of facts that can be used to draw a conclusion, make predictions and assist decision making.\n\nPublic health data may originate from various sources including:\n\n| Routine disease surveillance system such as hospital medical records (individual level information) or aggregated data captured through a reporting software - District Health Information Software (DHIS2)\n| Research and surveys - Demographic Health Survey, Malaria Indicator Survey, Survice Provision Assessment\n| Administrative - logistic data\n| Vital statistics - birth, death and marriage\n| Literature and reports\n\n-   ::: {.callout-tip appearance=\"simple\"}\n    -   `ls()` - Lists all active files.\n\n    -   `rm(list = ls())` - Cleans your environment.\n\n    -   `Ctrl + L` - Cleans the console.\n\n    -   Assign function: `Alt + -`.\n\n    -   `Ctrl + 1` - shortcut to move to source pane\n\n    -   `Ctrl + 2` - shortcut to move to console pane\n    :::\n\n## Step-by-Step Guide\n\n### 1. Setting Up Your Environment\n\nCheck your working directory using:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngetwd()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"C:/Users/User/OneDrive/Documents/GitHub/yalemgelaw.github.io/posts/2024-06-10-Data-manipulation-in-dplyr\"\n```\n\n\n:::\n:::\n\n\n### 2. Load the necessary packages\n\nFor data management, you will use the `tidyverse` package. Install the package if you haven't installed before using *install.packages(\"*tidyverse\"*)* function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)   # To read Excel files\nlibrary(janitor)  # To clean column names\nlibrary(dplyr) # For data wrangling\nlibrary(dplyr)    # For data manipulation\nlibrary(lubridate) # date function\n```\n:::\n\n\n### 3. Reading and Cleaning Data\n\nRead the malaria data: The data I used for this post is a sample of routine malaria surveillance data from **Ethiopia**. The data youre collected monthly and collated at the district level (third administrative system) and stored in csv file format.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmalaria_data <- read_csv(\"C:/Users/User/Documents/R_training/Tutorial_R/data/routine_data.csv\")\n```\n:::\n\n\n**Safeguard your data: Make a backup of the data**:\n\nWhen dealing with large datasets, it’s essential to take precautions. Imagine your data disappearing into the digital abyss—scary, right? To prevent that, always make a backup. Think of it as a safety net for your precious data. Whether you’re crunching numbers, visualizing trends, or building models, follow this golden rule: **Back it up before you hack it up**🔒!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data <- malaria_data #Make a backup \n```\n:::\n\n\n### 3. Skimm the data\n\nKnowing your dataset well from file size to data types is another crucial step prior to hands-on data cleaning.\n\nTo look at how the data looks like either by clicking on it in the global environment window or by typing the command `View(routine_data)` which opens up a window displaying the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nView(routine_data)\n```\n:::\n\n\n![*View data*](media/data_view.png)\n\nAlternatively, you may just want to look at a few rows. You can do this by using the `head()` function, which shows us the first six rows of data and `tail()` function, which shows us the lass six rows of the data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(routine_data) # top six rows\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntail(routine_data) # bottom six rows\n```\n:::\n\n\nTo understand the structure of the data you can use the `str()` command or `glimpse().`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(routine_data)\n```\n:::\n\n\nFrom the above results, you can see that the data frame consists of 11,604 observations (rows) and 14 variables (columns). Each variable's name and data type is also listed. The dataset can be read as `data.frame`, `lists`, `tbl_df`, `spatial`. Please refre my previous post on [**Mastering RStudio: A Beginner’s Guide**](https://yalemzewodgelaw.com/tutorials/2022-05-24-introduction-to-rstudio/)for detail note about data structure in R and supplementary [YouTube videos .](https://youtu.be/7MyAEQO3nqM?si=K0l2q8kU2hYaMUiW)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(routine_data)\n```\n:::\n\n\nFor a data frame you can select the nth row, or the nth column using square brackets (note where the comma is paced).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(routine_data[,2], 5) #second column\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data[1,] #firts row\n```\n:::\n\n\nTo view all variable names with the `names()`, `colnames()` , and `variable.names()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolnames(routine_data)\nnames(routine_data)\nvariable.names(routine_data)\n```\n:::\n\n\nTo view variable with the position number:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(routine_data)[5]\n```\n:::\n\n\nThere are several incorrect data types in this dataset, but let's continue using the \"date\" variable to demonstrate how to identify and update these errors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntypeof(routine_data$date)\n```\n:::\n\n\n\"Character\" is returned but the variable should in fact be a date. you can use the `as.Date` function of `lubridate` package to change the data type accordingly:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n as.Date(routine_data$date) # to date\n```\n:::\n\n\n![*Convert to date from a character variable*](media/date.png)\n\nString inconsistencies: This includes typos, capitalization errors, misplaced punctuation, or similar character data errors that might interfere with data analysis. Take for instance your \"Year\" column. As you can see there are wrongly entered year 21 and 3021.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  unique(Year)\n```\n:::\n\n\n**Outliers**:\n\nThe dataset has 8 continuous variables: *test_performed*, *confirmed_all, confirmed_u5, confirmed_5_14, confirmed_15, population, pop_5, pop_514, pop_15*. To get a feeling for how the data is distributed, you can plot histograms for case variables:\n\nUnder 5 confirmed malaria cases:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(routine_data$confirmed_u5)\n```\n:::\n\n\nAll age confirmed malaria cases:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(routine_data$confirmed_all)\n```\n:::\n\n\nData cleaning is one of the most important steps for analysis! No matter where your data comes from, always be sure the completeness, consistency, and trustworthiness of data before analyzing and utilizing the data. Once you get cleaned and organized, you can perform analysis to find clear and objective answers to any data question.\n\n## Data manipulation in dplyr()\n\nIn this section, you’ll explore the powerful dplyr package, part of the tidyverse ecosystem. Tidyverse is a collection of R packages for data science, designed to make cleaning and analyses of data easy and tidy.\n\n**dplyr** streamlines your data wrangling process, making it easier to work with data frames.\n\nLet’s dive into the key functions:\n\n::: callout-note\n***select()***: Choose specific variables (columns) from a data frame based on their names.\n\n***rename()***: Transform and rename variables.\n\n***filter()***: Select rows that meet specific criteria.\n\n***mutate()***: Create new variables by applying functions to existing ones.\n\n***group_by()***: Perform operations by group.\n\n***summarize()***: Aggregate data.\n\n***arrange()***: Order rows based on a specified column.\n\n***distinct()***: Remove duplicate rows based on specified columns.\n:::\n\nThese functions simplify common data manipulation tasks.\n\n#### The Pipe Operator `%>% OR \"|>\"`\n\nThis operator allows you to chain commands together. Instead of creating intermediate variables, you can directly link functions.\n\nyou use `pipes` when you creating intermediate variables to link commands together . For example, the idea is instead of using :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(routine_data, Year)\n```\n:::\n\n\nbuilding blocks that code readability and reproducibility, making your data workflows more efficient.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  select(Year)\n```\n:::\n\n\n#### Selecting Columns:\n\nThe `select()` function in R allows you to choose specific columns (variables) from a data frame. Specify the data frame name as the first argument, followed by the column names you want to keep. Example:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  select(region,zone,district, \n       Month,date,confirmed_all,test_performed)\n```\n:::\n\n\nTo select columns that have common prefix or suffix, you can use the `start_witth()` `contains()`, or `end_with()` functions. Example to subset columns that captured confirmed cases\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  select(\n    starts_with(\"confirmed\")\n  )\n```\n:::\n\n\ncontains()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  select(\n    contains(\"confirmed\")\n  )\n```\n:::\n\n\nend_with()\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  select(\n    ends_with(\"5\")\n  )\n```\n:::\n\n\n#### Filtering Rows:\n\nThe `filter()` function helps you retain only the rows (observations) that meet specific conditions.\n\nFor instance: To select rows for the *Tigray* region:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data%>% \n  filter(region == \"Tigray\")\n```\n:::\n\n\nTo choose rows with more than 500 confirmed cases in children under 5:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  filter(confirmed_u5 > 500)\n```\n:::\n\n\nTo filter by multiple conditions (e.g., regions “Amhara” or “Afar” with at least 500 confirmed cases in children under 5):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  filter(\n    (region == \"Amhara\" | region == \"Afar\") &\n    (confirmed_u5 >= 500))\n```\n:::\n\n\n| *Identifying Erroneous Data:*\n\nYou can use `filter()` to spot inconsistencies. For instance, find rows where the number of confirmed cases exceeds the number tested:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  filter(confirmed_all > test_performed)\n```\n:::\n\n\n#### Renaming variable\n\nThere may be situations when you want to rename variables in a data frame to make it more comprehensive and easier to process. The `rename()` function allows you to change column names in a data frame. It’s useful for making variable names more descriptive. you pass to this function the data frame you are working with, *`rename(dataframe, new_name = old_name).`*\n\nExample, if you wanted to change the variable \"confirmed_u5\" to \"conf_u5\", and to overwrite the object \"routine_data\" with this you would simply write:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  rename(conf_u5 =confirmed_u5)\n```\n:::\n\n\n#### Creating new variable\n\nThe ***`mutate()`*** function lets you add new variables or modify existing ones. You use the **`=`** sign to assign new values . For example, to calculate the incidence rate of malaria in children under five per 1000 population using the formula `(confirmed_u5 / pop_5) * 1000`, you could write:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  mutate(incidence_rate = (confirmed_u5/pop_5)*1000)\n```\n:::\n\n\n#### Altering existing variable\n\nSuppose you noticed an error in the region name, where “South Western Ethiopia” was mistakenly entered as “Sou.” You can correct this using an **`ifelse`** statement within **`mutate()`**. The condition is **`region == \"Sou\"`**, and if it’s met, you replace the value with “South Western Ethiopia.” Otherwise, you keep the original value.\n\nHere’s how you can do it:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  mutate(region = \n           ifelse(region == \"Sou\",\n                  \"South Western Ethiopia\",\n                  region)) \n```\n:::\n\n\nThis will update the **`region`** variable in your data frame.\n\n| Using `case_when` for Multiple Changes:\n\nIf you need to make multiple changes based on different conditions, consider using **`case_when`** instead of `ifelse`. Let’s say there are other errors in the district names. You can correct them simultaneously using **`case_when`**.\n\nThere is a district name mismatch between district names in **DHIS2** and names in **shapefile**. For this you will use the `task_data.csv`\n\n\n\n\n\n![district_old vs district_new](media/name_change.png)\n\nchange the Year column\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  mutate(Year = \n    case_when(Year == 21 ~ 2021,\n              Year == 3021 ~ 2021,\n              .default = Year\n              )\n  ) \nunique(routine_data$Year)\n```\n:::\n\n\n#### Removes duplicate rows\n\nThe distinct() function removes duplicate rows from a data frame based on specified columns. You can use it to keep only unique rows or to remove duplicates based on specific columns.\n\nTo remove duplicate rows based on the district column, you can use:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  distinct(district,\n           .keep_all = TRUE)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  select(district) %>% \n  distinct() %>% \n  count()\n```\n:::\n\n\n#### Null values\n\nNull values are treated differently in R. They appear as `NA` in the dataset, so you may expect the following code to work for filtering data to remove all missing values for the number of people tested for malaria:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  filter(test_performed =NA)\n```\n:::\n\n\nHowever, this does not work as R has a special way of dealing with missing values. You use the `is.na()` command, which checks fo `NA` values. As with the equals command, if you want the reverse of this, i.e. \"not NA\" you can use `!is.na()`. So the code to remove missing values would be:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  filter(!is.na(test_performed))\n```\n:::\n\n\nAnother method for removing missing data in tidyverse is using the `drop_na()` function from *{tidyr}* package. As with the filter function this takes the dataset as the first argument, followed by the variables for which you are dropping NA values.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data_no_NA <- routine_data %>% \n  drop_na(test_performed)\n```\n:::\n\n\n#### Sorting and reordering data frames\n\nSorting a data frame by rows and reordering columns is easy in R. To sort a data frame by a column you use the function `arrange()`. You specify the data frame and the column to sort by, and the default is to sort in `ascending` order. To sort in a descending order you can specify this with `desc().` Additionally, you can sort by multiple variables, and sorting will be undertaken in the order they appear in the command.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  arrange(confirmed_u5) # the default is asce\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  arrange(desc(confirmed_u5))\n```\n:::\n\n\nHow to change the order of the column\n\nThe `relocate()` function is part of the `dplyr` package in R. It allows you to change the order of columns in a data frame. You can specify where a particular column should be placed relative to other columns using the `.before` and `.after` arguments.\n\nThe basic syntax of the relocate() function as follows:\n\n`relocate(data, column_name, .before = target_column, .after = target_column)`\n\n-   **`data`**: The data frame containing the columns.\n\n-   **`column_name`**: The name of the column you want to move.\n\n-   **`.before`**: Specify the column name before which the target column should be placed.\n\n-   **`.after`**: Specify the column name after which the target column should be placed.\n\n**Example:** Suppose we have a data frame called **`task_data`** with columns: “zone,” “district,” and “Month.” We want to move the “district” column after the “zone” column and before the “Month” column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_data %>% \n  relocate(district, .before =  Month)\n```\n:::\n\n\n![Relocate](media/relocate.png)\n\n#### Summarising data\n\nThere are some useful functions in tidyverse to help you summarise the data. The first of these is the `count()` function. This is a quick function which will allow you to quickly count the occurrences of an item within a dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  filter(region==\"Amhara\") %>% \n  group_by(region) %>% \n  count(district)\n```\n:::\n\n\nBy including multiple variables in the command you can count the numbers of times that combination of variables appears.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n  count(region, Month)\n```\n:::\n\n\nIf you want to summarise numerical variables you can use the function `summarise().` This is used in conjunction with other mathematical functions such as `sum()`, `mean()`, `median()`, `max()`..\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntask_data %>% \n  summarise(total_case = sum(female, male, na.rm = TRUE),\n          mean_cases = mean(conf_5),\n          median_cases = median(conf_5),\n          max_cases = max(conf_5),\n          sd_case = sd(conf_5))\n```\n:::\n\n\nyou can combine the `summarise()` function with `group_by()` to summarise the data by different variables in the dataset. To calculate the total number of people tested and positive for malaria in each district in our dataset, you would group by this variable first and then summarise the data. Grouping is not restricted to one variable, if you wanted to group the data by location and date then both variables would be included in the command. When you use the `sum()` function , `na.rm = T` logic required if the column has NULL valuses\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>%  group_by(region) %>% \nsummarise(total_test = sum(test_performed),\n\n          total_positive = sum(confirmed_all),\n\n          total_u5 = sum(confirmed_u5),\n\n          total_514 = sum(confirmed_5_14),\n\n          total_ov15 = sum(confirmed_15)) \n```\n:::\n\n\n**Subsetting data**\n\n-   Subsetting refers to extracting a portion of your data based on specific conditions. In this case, we want to focus on data related to the Amhara region.\n\n-   The **`select()`** function allows us to choose specific columns from our data frame. We’ll keep the following columns: “region,” “zone,” “district,” “test_performed,” “confirmed_all,” and “confirmed_u5.”\n\n-   We’ll group our data by the “zone” column using the **`group_by()`** function. This means that subsequent calculations will be performed within each zone.\n\n-   The **`summarise()`** function computes summary statistics for each group (in this case, each zone).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data %>% \n select(region, zone, district,\n         test_performed,confirmed_all,confirmed_u5) %>%  \n         filter(region%in%\"Amhara\") %>%  \n  group_by(zone) %>% \n  summarise(total_positive = sum(confirmed_all, na.rm = T),\n          total_u5 = sum(confirmed_u5, na.rm = T),\n          prop_u5 = round((total_u5/total_positive)*100,2))\n```\n:::\n\n\nKnow to take everything you have learnt to import and clean the routine dataset. If you want your output to contain the total numbers of malaria tests performed and the number of confirmed cases in children under 5, people over 5, and calculate a total for all ages. you want to have the total by district level and Year in the dataset. This is how you would go about building the code.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroutine_data <- read_csv('~/Part 2/routine_data.csv',\n                         na = c(0, \"NA\", -9999))\n\nclean_routine_data <- routine_data %>% \ndplyr::select(region, zone, district, Month, Year,\n         test_performed,confirmed_all,\n         confirmed_u5,confirmed_5_14,confirmed_15) %>% \n  drop_na(test_performed,confirmed_all,\n         confirmed_u5,confirmed_5_14,confirmed_15) %>% \n  filter(test_performed>confirmed_all) %>% \n  mutate(region = case_when(region =='Sou'~'South Western Ethiopia',\n             TRUE~region),\n             year = case_when(Year == 3021 ~ 2021,\n                          Year == 21 ~ 2021,\n                          TRUE ~ Year),\n         date_reported = make_date(year = Year,\n                                   month = Month), \n         conf_ov5 = confirmed_5_14+confirmed_15) %>%\n  group_by(region, zone, district) %>% \n  summarise(test_total = sum(test_performed),\n            conf_total = sum(confirmed_all),\n            conf_u5 = sum(confirmed_u5),\n           conf_ov5 = sum(conf_ov5)) |> \n  dplyr::select(-test_total, -conf_total)\nhead(clean_routine_data)\n```\n:::\n\n\n### Advanced manipulation of data frames\n\nIn this section you introducing some more advanced functions for data manipulation. you will be using the \"clean_routine_data\" dataset you just created.\n\n#### Reshshaping data\n\nReshaping or pivoting data is an important part of data cleaning and manipulation. Tidyverse has introduced the functions `pivot_wider()` and `pivot_longer()` to improve the ease of reshaping data in R.\n\n`pivot_longer()` takes a wide dataset and converts it into a long one, decreasing the number of columns and increasing the number of rows. Datasets are often created in a wide format, but for analysis a long format is often preferable, especially for data visualisations.\n\nTo reshape the data long you need to pass the argument the columns which are being pivoted, a name for the new column to identify the columns being reshaped, and a name for the values of the columns being reshaped. you can also combine this with helper functions such as `starts_with()` to help identify the columns to reshape. For this demonstration you will use the \"clean_data_routine.csv\". To reshape the dataset into long format :\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_routine_data <- read_csv(\"C:/Users/User/Documents/R_training/Tutorial_R/data/clean_routine_data.csv\")\n\nclean_long <- clean_routine_data %>% \npivot_longer(cols = starts_with(\"conf\"),\n               names_to = \"age_group\",\n               names_pattern = \"conf_(.*)\",\n               values_to = 'cases') \n```\n:::\n\n\nto convert the 'clean_long' dataset to wide forma:\\\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_long |> \n  pivot_wider(id_cols = c('region',\n                          'zone',\n                          'district'),\n              names_from = age_group,\n              values_from = cases)\n```\n:::\n\n\nThere are a range of different options in this function to help pivot the data in the cleanest way possible. To see these you can look at the vignette by typing the code `vignette(\"pivot\")`.\n\n#### Joining data frames\n\nIn R you can easily join two data frames together based on one, or multiple variables. There are the following options for joining two data frames, `x`and `y`:\n\n-   `inner_join()`: includes all rows that appear in both x and y\n\n-   `left_join()`: includes all rows in x\n\n-   `right_join()`: includes all rows in y\n\n-   `full_join()`: includes all rows in x or y\n\n-   `anti_join()`: return all rows in one data frame that do not have matching values in another data frame\n\nTo run the command you need to pass it the data frames you wish to join and the variable(s) you wish to join by. If there are matching variables in the data frames these will be detected and you do not need to specify them.\n\nIf you have two data frames with varying numbers of rows, you can investigate the outcomes of using the different join commands. Firstly, you create two data frames of different lengths, `tested`, and `confirmed`, then look at what the commands and outcomes would be.\n\n![Data frame Joining in dplyr](tutorials/2024-06-10-Data-manipulation-in-dplyr/join.png)\n\n![Data frame Joining in dplyr](media/join.png)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntested <- data.frame(year = c(2015, 2016, 2017, 2018, 2019, 2020),\n\n                     tested = c(1981, 1992, 2611, 2433, 2291, 2311))\n\npositive <- data.frame(year = c(2013, 2014, 2015, 2016, 2017, 2018),\n\n                     positive = c(1164, 1391, 981, 871, 1211, 998))\n\n# Command written in full\n\ninner_join(tested, positive, by = \"year\") \n\n# Using the pipe operator\n\ntested %>% \n  inner_join(positive)      # Keeps only matching records\n\n left_join(tested, positive)     # Keeps all records for the first dataset\n\ntested %>% right_join(positive)    # Keeps all records for the second dataset \n\ntested %>% full_join(positive)   # Keeps all records from both datasets\n\nanti_join(tested, positive) #Keep all rows in tested that do not have matching values in positive dataset\n```\n:::\n\n\nYou can also join datasets which have different names for the variables you wish to join on. Say if the variable for \"year\" in the positive dataset was \"yr\", you could use the command:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npositive <- data.frame(yr = c(2013, 2014, 2015, 2016, 2017, 2018),\n                     positive = c(1164, 1391, 981, 871, 1211, 998))\ntested %>% inner_join(positive,\n                      by= c(\"year\"=\"yr\"))\n```\n:::\n\n\n#### Writing data\n\nOnce you have finished working on your data there are multiple ways you can save your work in R.\n\nOne of the basic ones is to save your dataset as a csv. This is useful as it can easily be opened in other software (such as excel). You may also want to save your data as a Stata (dta) file.\n\nR has some specific formats you can use to store data, these are `.RDS` and `.RData`. RDS files store one R object, whilst RData can store multiple objects.\n\nHere, you can select which format you want to save the data in and save the `malaria_incidence_2021` data frame you created in this module.\n\nSimilarly to importing data, you can use the base R functions of \\`write.csv()\\`, or preferably the `tidyverse` option if `write_csv()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_csv(clean_routine_data, \"clean_routine_data.csv\")\n\nwrite_dta(clean_routine_data, \"outputs/clean_routine_data.dta\")\n\nsaveRDS(clean_routine_data, \"outputs/clean_routine_data.RDS\")\n```\n:::\n\n\n# Reference\n\n1.  [MAP training material](https://malaria-atlas-project.gitlab.io/intro-to-spatial-analysis-for-infectious-diseases/02_datahandling.html) \n\n2.  [R for Reproducible Scientific Analysis](https://umn-dash.github.io/r-novice-gapminder/aio.html)\n\n3.  [Dataframe Manipulation with dplyr](https://r-crash-course.github.io/13-dplyr/)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}